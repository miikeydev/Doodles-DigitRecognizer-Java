import data.Image_;
import org.deeplearning4j.datasets.iterator.utilty.ListDataSetIterator;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.layers.DenseLayer;
import org.deeplearning4j.nn.conf.layers.OutputLayer;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.weights.WeightInit;
import org.nd4j.linalg.activations.Activation;
import org.nd4j.linalg.api.buffer.DataType;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.factory.Nd4j;
import org.nd4j.linalg.indexing.NDArrayIndex;
import org.nd4j.linalg.learning.config.IUpdater;
import org.nd4j.linalg.lossfunctions.LossFunctions;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.nd4j.linalg.learning.config.Adam;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;

import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;
import org.nd4j.linalg.dataset.DataSet;
import data.DataReader;
import data.DataConverter;





public class SuperNeuralNetwork {
    private static MultiLayerNetwork network;

    public SuperNeuralNetwork(int numInputs, int numOutputs, double learningRate) {
        int seed = 123;
        int numHidden = 100; // You can adjust this based on your needs

        // Create a configuration for the neural network
        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
                .seed(seed)
                .updater(new Adam(learningRate))
                .weightInit(WeightInit.XAVIER)
                .list()
                .layer(0, new DenseLayer.Builder()
                        .nIn(numInputs)
                        .nOut(numHidden)
                        .activation(Activation.RELU)
                        .build())
                .layer(1, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)
                        .nIn(numHidden)
                        .nOut(numOutputs)
                        .activation(Activation.SOFTMAX)
                        .build())
                .build();

        network = new MultiLayerNetwork(conf);
        network.init();

        // Listener to print the score every iteration
        network.setListeners(new ScoreIterationListener(1));
    }


    public void train(INDArray X, INDArray Y, int epochs, double learningRate, int displayInterval) {
        for (int i = 0; i < epochs; i++) {
            network.fit(X, Y);

            if ((i + 1) % displayInterval == 0) {
                double score = network.score();
                System.out.println("Epoch " + (i + 1) + " - Score: " + score);
            }
        }
    }

    public double evaluateAccuracy(INDArray X, INDArray Y) {
        int totalExamples = X.rows();
        int correctPredictions = 0;

        for (int i = 0; i < totalExamples; i++) {
            INDArray input = X.getRow(i, true);
            INDArray label = Y.getRow(i, true);

            INDArray predicted = network.output(input, false);

            int actualLabel = label.argMax(1).getInt(0);
            int predictedLabel = predicted.argMax(1).getInt(0);

            if (actualLabel == predictedLabel) {
                correctPredictions++;
            }
        }

        double accuracy = (double) correctPredictions / totalExamples;
        return accuracy;
    }



    public INDArray oneHotEncoding(INDArray Y, int numClasses) {
        int totalExamples = Y.rows();
        INDArray oneHot = Nd4j.zeros(totalExamples, numClasses);

        for (int i = 0; i < totalExamples; i++) {
            int label = Y.getInt(i);

            // Set the corresponding element to 1
            oneHot.putScalar(new int[]{i, label}, 1.0);
        }

        return oneHot;
    }

    public INDArray predict(INDArray input) {
        return network.output(input, false);
    }

    // Create a DataSetIterator from your data

    public static void main(String[] args) {
        int numInputs = 784; // Adjust based on your input size
        int numOutputs = 10; // Adjust based on your output size
        double learningRate = 0.1;
        int numEpochs = 15;  // Number of training epochs
        int displayInterval = 1;

        // Load your training data and labels
        data.DataReader reader = new data.DataReader();
        List<Image_> trainingData = DataReader.readData("src/resources/train.csv"); // Replace with the actual path
        INDArray[] trainingDataArrays = DataConverter.convertToINDArrays(trainingData);
        INDArray yourTrainingData = trainingDataArrays[0];
        INDArray yourLabels = trainingDataArrays[1];

        SuperNeuralNetwork superNN = new SuperNeuralNetwork(numInputs, numOutputs, learningRate);

        // One-hot encode the labels
        int numClasses = numOutputs; // Replace with the actual number of classes
        INDArray oneHotLabels = superNN.oneHotEncoding(yourLabels, numClasses);

        // Train the network
        superNN.train(yourTrainingData, oneHotLabels, numEpochs, learningRate, displayInterval);

        // Evaluate accuracy
        double accuracy = superNN.evaluateAccuracy(yourTrainingData, oneHotLabels);
        System.out.println("Accuracy: " + accuracy);
    }

}
